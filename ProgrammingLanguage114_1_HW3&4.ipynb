{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6h+ncPdCaEpMH1Su/IgyK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Disaster4255/PL_REPO_PY_Hao/blob/main/ProgrammingLanguage114_1_HW3%264.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ç•ªèŒ„é˜ä»£è¾¦äº‹é …èˆ‡çˆ¬èŸ²\n",
        "æ–°å¢\"åˆªé™¤ä»»å‹™åŠŸèƒ½\"èˆ‡\"ä»¥CSVæˆ–JSONåŒ¯å‡ºåŠŸèƒ½\"<br>\n",
        "çˆ¬èŸ²éƒ¨åˆ†æ”¹ç‚ºæ“·å–å¾Œç›´æ¥åˆ†ææ–‡æœ¬ä¸¦é¡¯ç¤ºå‰ä¸‰ç†±è©ï¼Œå†è¼¸å‡ºAIç°¡çŸ­çµè«–\n"
      ],
      "metadata": {
        "id": "b6VXZ-z0hAk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install gspread gspread_dataframe google-auth google-auth-oauthlib google-auth-httplib2 \\\n",
        "               gradio pandas beautifulsoup4 google-generativeai python-dateutil"
      ],
      "metadata": {
        "id": "TgvI19dJd6Xk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, uuid, re, json, datetime\n",
        "from datetime import datetime as dt, timedelta\n",
        "from dateutil.tz import gettz\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter # æ–°å¢ï¼šç”¨æ–¼è©é »çµ±è¨ˆ\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import GenerationConfig # å¼•å…¥ GenerationConfig\n",
        "import jieba # æ–°å¢ï¼šä¸­æ–‡åˆ†è©åº«\n",
        "\n",
        "# Google Auth & Sheets\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe, get_as_dataframe\n",
        "from google.auth.transport.requests import Request\n",
        "from google.oauth2 import service_account\n",
        "from google.auth import default\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# å¾ Colab Secrets ä¸­ç²å– API é‡‘é‘°\n",
        "# ç¢ºä¿æ‚¨å·²ç¶“åœ¨ Colab Secrets ä¸­è¨­å®šäº† 'gemini_key'\n",
        "api_key = userdata.get('gemini_key')\n",
        "\n",
        "# ä½¿ç”¨ç²å–çš„é‡‘é‘°é…ç½® genai\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# æª¢æŸ¥ API key æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œå‰‡æœƒæ˜¯ None æˆ–ç©ºå­—ä¸²\n",
        "API_KEY_IS_CONFIGURED = bool(api_key)\n",
        "\n",
        "# çµ±ä¸€ä½¿ç”¨ flash æ¨¡å‹ä»¥åŠ å¿«é€Ÿåº¦å’Œæå‡ç©©å®šæ€§\n",
        "GEMINI_MODEL = 'gemini-2.5-flash'\n",
        "\n",
        "\n",
        "SHEET_URL = \"https://docs.google.com/spreadsheets/d/162pRL7bo8TP6n_ebBqC8pDl_dlVbXab09XYwRoAHpoQ/edit?usp=sharing\"\n",
        "WORKSHEET_NAME = \"å·¥ä½œè¡¨4\"\n",
        "TIMEZONE = \"Asia/Taipei\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "# read data and put it in a dataframe\n",
        "# åœ¨ google å·¥ä½œè¡¨è¼‰å…¥ gsheets\n",
        "gsheets = gc.open_by_url(SHEET_URL)\n",
        "\n",
        "\n",
        "# å¾ gsheets çš„ All-whiteboard-device è¼‰å…¥ sheets\n",
        "sh = gsheets.worksheet(WORKSHEET_NAME).get_all_values()\n",
        "# å°‡ sheets1 è³‡æ–™è¼‰å…¥ pd çš„ DataFrame é€²è¡Œåˆ†æ\n",
        "df = pd.DataFrame(sh[1:], columns=sh[0])\n",
        "# å–å¾—æœ€å‰é¢çš„5ç­†è³‡æ–™\n",
        "df.head()\n",
        "\n",
        "\n",
        "# ä¸­æ–‡åŸºæœ¬åœç”¨è©åˆ—è¡¨ (ç”¨æ–¼ Jieba åˆ†è©å¾Œéæ¿¾)\n",
        "CHINESE_STOP_WORDS = set([\n",
        "    'çš„', 'å¾—', 'åœ°', 'æ˜¯', 'æœ‰', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'å€‘', 'é€™', 'é‚£',\n",
        "    'å€‹', 'äº†', 'å’Œ', 'èˆ‡', 'æˆ–', 'ä½†', 'è€Œ', 'å‰‡', 'ä¹Ÿ', 'éƒ½', 'ä¸', 'å¾ˆ', 'å°‡', 'æœƒ',\n",
        "    'å¯ä»¥', 'èƒ½å¤ ', 'å› ç‚º', 'æ‰€ä»¥', 'é›–ç„¶', 'ä½†æ˜¯', 'ç„¶è€Œ', 'å› æ­¤', 'ç‚ºäº†', 'ä»¥ä¾¿', 'ä»¥è‡´æ–¼',\n",
        "    'å°æ–¼', 'é—œæ–¼', 'ç”±æ–¼', 'è‡³æ–¼', 'ç›´åˆ°', 'å¾', 'å‘', 'çµ¦', 'è¢«', 'è®“', 'å«', 'å°‡', 'æŠŠ',\n",
        "    'å°', 'ç‚º', 'æ™‚', 'æ—¥', 'å¹´', 'æœˆ', 'è™Ÿ', 'åˆ†', 'ç§’', 'å¦‚', 'ç­‰', 'ä¹‹', 'æ‰€', 'å…¶',\n",
        "    'ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å', 'åƒ', 'è¬', 'å„„', 'å…ƒ',\n",
        "    'äººæ°‘å¹£', 'ç¾å…ƒ', 'è‹±éŠ', 'æ­å…ƒ', 'æ—¥åœ“', 'æ˜¯', 'èªª', 'é€™', 'å€‹', 'äºº', 'ä»€éº¼', 'æ€éº¼',\n",
        "    'ä¸€å€‹', 'ä¸€äº›', 'ä¸€äº›', 'ä¸€äº›', 'ä¸€äº›', 'ä¸€äº›', 'æ²’æœ‰', 'ä¸å¯', 'å°±æ˜¯', 'ä¸€å€‹',\n",
        "    # æ¨™é»ç¬¦è™ŸåŠç©ºç™½\n",
        "    'ï¼Œ', 'ã€‚', 'ã€', 'ï¼Ÿ', 'ï¼', 'ï¼š', 'ï¼›', 'â€œ', 'â€', 'ã€Š', 'ã€‹', 'ï¼ˆ', 'ï¼‰', 'ã€', 'ã€‘',\n",
        "    '[', ']', '{', '}', '-', '_', '=', '+', '*', '/', '\\\\', '|', '<', '>', '~', '`',\n",
        "    '.', ',', '!', '?', ';', ':', '\"', \"'\", '...', '..', ' ', '\\n', '\\t', '\\r',\n",
        "    'â€™', 'â€œ', 'â€', 'ã€', 'ã€‘', 'ã€Œ', 'ã€', '...', 'â‹¯â‹¯', 'â€”', 'â”€â”€', '...',\n",
        "])\n",
        "\n",
        "\n",
        "def ensure_spreadsheet(name):\n",
        "    try:\n",
        "        sh = gc.open(name)  # returns gspread.models.Spreadsheet\n",
        "    except gspread.SpreadsheetNotFound:\n",
        "        sh = gc.create(name)\n",
        "    return sh\n",
        "\n",
        "sh = ensure_spreadsheet(WORKSHEET_NAME)\n",
        "\n",
        "\n",
        "def ensure_worksheet(sh, title, header):\n",
        "    try:\n",
        "        ws = sh.worksheet(title)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        ws = sh.add_worksheet(title=title, rows=\"1000\", cols=str(len(header)+5))\n",
        "        ws.update([header])\n",
        "    # è‹¥æ²’æœ‰è¡¨é ­å°±è£œä¸Š\n",
        "    data = ws.get_all_values()\n",
        "    if not data or (data and data[0] != header):\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "    return ws\n",
        "\n",
        "TASKS_HEADER = [\n",
        "    \"id\",\"task\",\"status\",\"priority\",\"est_min\",\"start_time\",\"end_time\",\n",
        "    \"actual_min\",\"pomodoros\",\"due_date\",\"labels\",\"notes\",\n",
        "    \"created_at\",\"updated_at\",\"completed_at\",\"planned_for\"\n",
        "]\n",
        "LOGS_HEADER = [\n",
        "    \"log_id\",\"task_id\",\"phase\",\"start_ts\",\"end_ts\",\"minutes\",\"cycles\",\"note\"\n",
        "]\n",
        "CLIPS_HEADER = [\"clip_id\",\"url\",\"selector\",\"text\",\"href\",\"created_at\",\"added_to_task\"]\n",
        "# æ–°å¢åˆ†æçµæœå·¥ä½œè¡¨é ­\n",
        "ANALYSIS_HEADER = [\"timestamp\", \"hot_word_1\", \"hot_word_2\", \"hot_word_3\", \"word_list_json\", \"gemini_conclusion\"]\n",
        "\n",
        "\n",
        "ws_tasks = ensure_worksheet(sh, \"tasks\", TASKS_HEADER)\n",
        "ws_logs  = ensure_worksheet(sh, \"pomodoro_logs\", LOGS_HEADER)\n",
        "ws_clips = ensure_worksheet(sh, \"web_clips\", CLIPS_HEADER)\n",
        "ws_analysis = ensure_worksheet(sh, \"keyword_analysis\", ANALYSIS_HEADER) # æ–°å·¥ä½œè¡¨\n",
        "\n",
        "def tznow():\n",
        "    return dt.now(gettz(TIMEZONE))\n",
        "\n",
        "def read_df(ws, header):\n",
        "    df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "    if df is None or df.empty:\n",
        "        return pd.DataFrame(columns=header)\n",
        "    df = df.fillna(\"\")\n",
        "    # ä¿è­‰æ¬„ä½é½Šå…¨\n",
        "    for c in header:\n",
        "        if c not in df.columns:\n",
        "            df[c] = \"\"\n",
        "    # å‹åˆ¥å¾®èª¿\n",
        "    if \"est_min\" in df.columns:\n",
        "        df[\"est_min\"] = pd.to_numeric(df[\"est_min\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "    if \"actual_min\" in df.columns:\n",
        "        df[\"actual_min\"] = pd.to_numeric(df[\"actual_min\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "    if \"pomodoros\" in df.columns:\n",
        "        df[\"pomodoros\"] = pd.to_numeric(df[\"pomodoros\"], errors=\"coerce\").fillna(0).astype(int)\n",
        "    return df[header]\n",
        "\n",
        "def write_df(ws, df, header):\n",
        "    if df.empty:\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "        return\n",
        "    # è½‰å­—ä¸²é¿å… gspread å‹åˆ¥å•é¡Œ\n",
        "    df_out = df.copy()\n",
        "    for c in df_out.columns:\n",
        "        df_out[c] = df_out[c].astype(str)\n",
        "    ws.clear()\n",
        "    ws.update([header] + df_out.values.tolist())\n",
        "\n",
        "def refresh_all():\n",
        "    return (\n",
        "        read_df(ws_tasks, TASKS_HEADER).copy(),\n",
        "        read_df(ws_logs, LOGS_HEADER).copy(),\n",
        "        read_df(ws_clips, CLIPS_HEADER).copy(),\n",
        "        read_df(ws_analysis, ANALYSIS_HEADER).copy() # æ–°å¢è¼‰å…¥åˆ†æçµæœ\n",
        "    )\n",
        "\n",
        "tasks_df, logs_df, clips_df, analysis_df = refresh_all() # æ›´æ–°è¼‰å…¥è®Šæ•¸\n",
        "\n",
        "# ====================================================================\n",
        "# ç•ªèŒ„é˜éšæ®µè¿½è¹¤è®Šæ•¸ (å¿…é ˆåœ¨å…¨å±€ç¯„åœå®šç¾©)\n",
        "current_task_phase = {} # ç”¨ä¾†è¿½è¹¤ä»»å‹™çš„ç‹€æ…‹ï¼š{\"task_id\": {\"phase\": \"work\", \"start_ts\": \"...\"}}\n",
        "# ====================================================================\n",
        "\n",
        "def add_task(task, priority, est_min, due_date, labels, notes, planned_for):\n",
        "    global tasks_df\n",
        "    _now = tznow().isoformat()\n",
        "    new = pd.DataFrame([{\n",
        "        \"id\": str(uuid.uuid4())[:8],\n",
        "        \"task\": task.strip(),\n",
        "        \"status\": \"todo\",\n",
        "        \"priority\": priority or \"M\",\n",
        "        \"est_min\": int(est_min) if est_min else 25,\n",
        "        \"start_time\": \"\",\n",
        "        \"end_time\": \"\",\n",
        "        \"actual_min\": 0,\n",
        "        \"pomodoros\": 0,\n",
        "        \"due_date\": due_date or \"\",\n",
        "        \"labels\": labels or \"\",\n",
        "        \"notes\": notes or \"\",\n",
        "        \"created_at\": _now,\n",
        "        \"updated_at\": _now,\n",
        "        \"completed_at\": \"\",\n",
        "        \"planned_for\": planned_for or \"\"  # å¯å¡« today / tomorrow / ç©ºç™½\n",
        "    }])\n",
        "    tasks_df = pd.concat([tasks_df, new], ignore_index=True)\n",
        "    write_df(ws_tasks, tasks_df, TASKS_HEADER)\n",
        "    return \"âœ… å·²æ–°å¢ä»»å‹™\", tasks_df\n",
        "\n",
        "\n",
        "def update_task_status(task_id, new_status):\n",
        "    global tasks_df\n",
        "    idx = tasks_df.index[tasks_df[\"id\"] == task_id]\n",
        "    if len(idx)==0:\n",
        "        return \"âš ï¸ æ‰¾ä¸åˆ°ä»»å‹™\", tasks_df\n",
        "    i = idx[0]\n",
        "    tasks_df.loc[i, \"status\"] = new_status\n",
        "    tasks_df.loc[i, \"updated_at\"] = tznow().isoformat()\n",
        "    if new_status == \"done\" and not tasks_df.loc[i, \"completed_at\"]:\n",
        "        tasks_df.loc[i, \"completed_at\"] = tznow().isoformat()\n",
        "    write_df(ws_tasks, tasks_df, TASKS_HEADER)\n",
        "    return \"âœ… ç‹€æ…‹å·²æ›´æ–°\", tasks_df\n",
        "\n",
        "def mark_done(task_id):\n",
        "    return update_task_status(task_id, \"done\")\n",
        "\n",
        "\n",
        "def delete_task(task_id):\n",
        "    global tasks_df\n",
        "    idx = tasks_df.index[tasks_df[\"id\"] == task_id]\n",
        "    if len(idx)==0:\n",
        "        # å›å‚³ 5 å€‹å€¼ï¼Œç©ºå€¼ç”¨ gr.update() ä¾†ç¶­æŒç¾ç‹€\n",
        "        return \"âš ï¸ æ‰¾ä¸åˆ°ä»»å‹™\", tasks_df, gr.update(), gr.update(), gr.update()\n",
        "\n",
        "    # åˆªé™¤ä»»å‹™\n",
        "    tasks_df = tasks_df.drop(idx).reset_index(drop=True)\n",
        "    write_df(ws_tasks, tasks_df, TASKS_HEADER)\n",
        "\n",
        "    # å› ç‚ºä»»å‹™è¢«åˆªé™¤äº†ï¼Œåˆ—è¡¨å¯èƒ½æ”¹è®Šï¼Œå›å‚³æ–°çš„ä»»å‹™é¸é …åˆ—è¡¨\n",
        "    new_choices = list_task_choices()\n",
        "\n",
        "    # å›å‚³ 5 å€‹è¼¸å‡ºå€¼ï¼šè¨Šæ¯ã€Dataframeã€task_choice æ›´æ–°ã€sel_task æ›´æ–°ã€task_choice_del æ›´æ–°\n",
        "    return (\n",
        "        \"ğŸ—‘ï¸ ä»»å‹™å·²åˆªé™¤\",\n",
        "        tasks_df,\n",
        "        gr.update(choices=new_choices),\n",
        "        gr.update(choices=new_choices),\n",
        "        gr.update(choices=new_choices)\n",
        "    )\n",
        "\n",
        "\n",
        "def recalc_task_actuals(task_id):\n",
        "    \"\"\"æ ¹æ“š logs_df å›å¯« actual_min èˆ‡ pomodoros\"\"\"\n",
        "    global tasks_df, logs_df\n",
        "    # ç¢ºä¿ logs_df æ˜¯æœ€æ–°çš„ï¼Œå› ç‚º end_phase å‰›å¯«å…¥\n",
        "    logs_df = read_df(ws_logs, LOGS_HEADER)\n",
        "\n",
        "    work_logs = logs_df[(logs_df[\"task_id\"]==task_id) & (logs_df[\"phase\"]==\"work\")]\n",
        "    total_min = work_logs[\"minutes\"].astype(float).sum() if not work_logs.empty else 0\n",
        "    pomos = int(round(total_min / 25.0))\n",
        "    idx = tasks_df.index[tasks_df[\"id\"]==task_id]\n",
        "    if len(idx)==0: return\n",
        "    i = idx[0]\n",
        "    tasks_df.loc[i,\"actual_min\"] = int(total_min)\n",
        "    tasks_df.loc[i,\"pomodoros\"] = pomos\n",
        "    tasks_df.loc[i,\"updated_at\"] = tznow().isoformat()\n",
        "\n",
        "def list_task_choices():\n",
        "    global tasks_df\n",
        "    if tasks_df.empty:\n",
        "        return []\n",
        "    # é¡¯ç¤ºï¼š [status] (P:priority) task  â€” id\n",
        "    def row_label(r):\n",
        "        return f\"[{r['status']}] (P:{r['priority']}) {r['task']} â€” {r['id']}\"\n",
        "    return [(row_label(r), r[\"id\"]) for _, r in tasks_df.iterrows()]\n",
        "\n",
        "# ====================================================================\n",
        "# ã€è£œé½Šã€‘ç•ªèŒ„é˜æ ¸å¿ƒåŠŸèƒ½ï¼šStart Phase\n",
        "# ====================================================================\n",
        "def start_phase(task_id, phase, cycles):\n",
        "    global current_task_phase, tasks_df\n",
        "    if not task_id:\n",
        "        return gr.update(value=\"âš ï¸ è«‹é¸æ“‡ä¸€å€‹ä»»å‹™é–‹å§‹ã€‚\")\n",
        "    if task_id in current_task_phase:\n",
        "        # é¡¯ç¤ºç•¶å‰é€²è¡Œä¸­çš„ä»»å‹™åç¨±\n",
        "        task_name = current_task_phase[task_id].get(\"task_name\", f\"ID: {task_id}\")\n",
        "        return gr.update(value=f\"âš ï¸ ä»»å‹™ {task_name} ä»åœ¨é€²è¡Œä¸­ï¼š{current_task_phase[task_id]['phase']}ã€‚\")\n",
        "\n",
        "    _now = tznow().isoformat()\n",
        "\n",
        "    # ç²å–ä»»å‹™åç¨±\n",
        "    task_row = tasks_df[tasks_df[\"id\"]==task_id]\n",
        "    task_name = task_row[\"task\"].iloc[0] if not task_row.empty else f\"ID: {task_id}\"\n",
        "\n",
        "    current_task_phase[task_id] = {\n",
        "        \"phase\": phase,\n",
        "        \"start_ts\": _now,\n",
        "        \"cycles\": int(cycles) if phase == \"work\" else 0, # åªæœ‰å·¥ä½œæ‰è¨ˆæ•¸\n",
        "        \"task_name\": task_name\n",
        "    }\n",
        "\n",
        "    if phase == \"work\":\n",
        "        idx = tasks_df.index[tasks_df[\"id\"] == task_id]\n",
        "        if len(idx)>0:\n",
        "            # æ›´æ–°ä»»å‹™çš„ start_time å’Œ status\n",
        "            if not tasks_df.loc[idx[0], \"start_time\"]:\n",
        "                tasks_df.loc[idx[0], \"start_time\"] = _now\n",
        "            if tasks_df.loc[idx[0], \"status\"] != \"done\":\n",
        "                tasks_df.loc[idx[0], \"status\"] = \"in-progress\"\n",
        "                tasks_df.loc[idx[0], \"updated_at\"] = _now\n",
        "                write_df(ws_tasks, tasks_df, TASKS_HEADER)\n",
        "            return gr.update(value=f\"ğŸš€ ä»»å‹™ï¼š{task_name} | é–‹å§‹ **å·¥ä½œ**ï¼Œç•ªèŒ„æ•¸ï¼š{cycles}ã€‚\")\n",
        "    else:\n",
        "        return gr.update(value=f\"ğŸµ ä»»å‹™ï¼š{task_name} | é–‹å§‹ **ä¼‘æ¯**ã€‚\")\n",
        "\n",
        "# ====================================================================\n",
        "# ã€è£œé½Šã€‘ç•ªèŒ„é˜æ ¸å¿ƒåŠŸèƒ½ï¼šEnd Phase\n",
        "# ====================================================================\n",
        "def end_phase(task_id, note):\n",
        "    global current_task_phase, logs_df, tasks_df\n",
        "\n",
        "    if task_id not in current_task_phase:\n",
        "        return gr.update(value=\"âš ï¸ æ‰¾ä¸åˆ°é€²è¡Œä¸­çš„éšæ®µï¼Œè«‹å…ˆé»æ“Šã€Œé–‹å§‹å·¥ä½œ/ä¼‘æ¯ã€ã€‚\")\n",
        "\n",
        "    phase_data = current_task_phase.pop(task_id) # ç§»é™¤éšæ®µ\n",
        "    _now = tznow()\n",
        "    # ä½¿ç”¨ fromisoformat è½‰æ›æ™‚é–“\n",
        "    try:\n",
        "        start_ts = dt.fromisoformat(phase_data[\"start_ts\"])\n",
        "    except ValueError:\n",
        "        # å¦‚æœæ™‚é–“æ ¼å¼æœ‰èª¤ï¼Œçµ¦ä¸€å€‹é è¨­å€¼ï¼Œé¿å…å´©æ½°\n",
        "        start_ts = _now - timedelta(minutes=1)\n",
        "\n",
        "    # è¨ˆç®—æ™‚é•·\n",
        "    duration = (_now - start_ts)\n",
        "    minutes = round(duration.total_seconds() / 60)\n",
        "\n",
        "    # è®€å– logs_df ä»¥ä¾¿é™„åŠ æ–°çš„ Log\n",
        "    logs_df = read_df(ws_logs, LOGS_HEADER)\n",
        "\n",
        "    # å¯«å…¥ Log\n",
        "    new_log = pd.DataFrame([{\n",
        "        \"log_id\": str(uuid.uuid4())[:8],\n",
        "        \"task_id\": task_id,\n",
        "        \"phase\": phase_data[\"phase\"],\n",
        "        \"start_ts\": phase_data[\"start_ts\"],\n",
        "        \"end_ts\": _now.isoformat(),\n",
        "        \"minutes\": minutes,\n",
        "        \"cycles\": phase_data[\"cycles\"],\n",
        "        \"note\": note or \"\"\n",
        "    }])\n",
        "    logs_df = pd.concat([logs_df, new_log], ignore_index=True)\n",
        "    write_df(ws_logs, logs_df, LOGS_HEADER)\n",
        "\n",
        "    # å¦‚æœæ˜¯ workï¼Œæ›´æ–°ä»»å‹™çš„å¯¦éš›æ™‚é–“å’Œç•ªèŒ„æ•¸\n",
        "    if phase_data[\"phase\"] == \"work\":\n",
        "        # æ›´æ–° tasks_df ä¸­çš„å¯¦éš›æ™‚é–“å’Œç•ªèŒ„æ•¸ï¼Œä¸¦å¯«å› Sheet\n",
        "        recalc_task_actuals(task_id)\n",
        "        write_df(ws_tasks, tasks_df, TASKS_HEADER)\n",
        "\n",
        "        # é‡æ–°è¼‰å…¥ logs_df (é›–ç„¶å·²ç¶“åœ¨ä¸Šé¢å¯«å…¥ï¼Œä½†ç¢ºä¿ Dataframe æ˜¯æœ€æ–°çš„)\n",
        "        logs_df_latest = read_df(ws_logs, LOGS_HEADER).copy()\n",
        "\n",
        "        # è¼¸å‡º 2 å€‹å€¼ï¼šè¨Šæ¯ (msg_pomo), Dataframe (grid_logs)\n",
        "        return gr.update(value=f\"âœ… ä»»å‹™ï¼š{phase_data['task_name']} | çµæŸ **å·¥ä½œ**ï¼Œè¨˜éŒ„ {minutes} åˆ†é˜ã€‚\"), logs_df_latest\n",
        "    else:\n",
        "        logs_df_latest = read_df(ws_logs, LOGS_HEADER).copy()\n",
        "        return gr.update(value=f\"ğŸ§˜ ä»»å‹™ï¼š{phase_data['task_name']} | çµæŸ **ä¼‘æ¯**ï¼Œè¨˜éŒ„ {minutes} åˆ†é˜ã€‚\"), logs_df_latest\n",
        "# ====================================================================\n",
        "\n",
        "# AI è¨ˆç•«ï¼ˆGeminiï¼›ç„¡é‡‘é‘°å‰‡è¦å‰‡å¼ï¼‰\n",
        "def generate_today_plan():\n",
        "    global tasks_df\n",
        "    # ä»¥ã€Œdue_date æ˜¯ä»Šå¤©ã€æˆ–ã€Œplanned_for = todayã€ä¸”ä¸æ˜¯ done çš„ä»»å‹™ç‚ºè¨ˆç•«æ¸…å–®\n",
        "    today = tznow().date().isoformat()\n",
        "    cand = tasks_df[\n",
        "        ((tasks_df[\"due_date\"]==today) | (tasks_df[\"planned_for\"].str.lower()==\"today\")) &\n",
        "        (tasks_df[\"status\"]!=\"done\")\n",
        "    ].copy()\n",
        "    if cand.empty:\n",
        "        return \"ğŸ“­ ä»Šå¤©æ²’æœ‰æ¨™è¨˜çš„ä»»å‹™ã€‚è«‹åœ¨ Tasks åˆ†é æŠŠä»»å‹™çš„ due_date è¨­ç‚ºä»Šå¤©æˆ– planned_for è¨­ç‚º todayã€‚\"\n",
        "\n",
        "    # å…ˆä¾ priorityï¼ˆH>M>Lï¼‰+ est_min æ’åº\n",
        "    pr_order = {\"H\":0, \"M\":1, \"L\":2}\n",
        "    cand[\"p_ord\"] = cand[\"priority\"].map(pr_order).fillna(3)\n",
        "    cand = cand.sort_values([\"p_ord\",\"est_min\"], ascending=[True, True])\n",
        "\n",
        "    # æª¢æŸ¥ API_KEY_IS_CONFIGURED (ä½¿ç”¨å…¨å±€è®Šé‡)\n",
        "    plan_md = \"\" # å…ˆåˆå§‹åŒ–ç‚ºç©º\n",
        "\n",
        "    if API_KEY_IS_CONFIGURED:\n",
        "        sys_prompt = (\n",
        "            \"ä½ æ˜¯ä¸€ä½ä»»å‹™è¦åŠƒåŠ©ç†ã€‚è«‹æŠŠè¼¸å…¥çš„ä»»å‹™ï¼ˆå«ä¼°æ™‚èˆ‡å„ªå…ˆç´šï¼‰æ’æˆä¸‰æ®µï¼šmorningã€afternoonã€eveningï¼Œ\"\n",
        "            \"ä¸¦çµ¦å‡ºæ¯æ®µçš„é‡é»ã€é †åºã€æ¯é …çš„æ™‚é–“é ä¼°èˆ‡å‚™è¨»ã€‚ç¸½æ™‚æ•¸è«‹å¤§è‡´ç¬¦åˆä»»å‹™ä¼°æ™‚ç¸½å’Œã€‚\"\n",
        "            \"å›å‚³ä»¥ Markdown æ¢åˆ—ï¼Œæ ¼å¼ï¼š\\n\"\n",
        "            \"### Morning\\n- [ä»»å‹™ID] ä»»å‹™åç¨±ï¼ˆé ä¼° xx åˆ†ï¼‰â€” å‚™è¨»\\n...\"\n",
        "            \"### Afternoon\\n...\\n### Evening\\n...\\n\"\n",
        "        )\n",
        "        items = []\n",
        "        for _, r in cand.iterrows():\n",
        "            items.append({\n",
        "                \"id\": r[\"id\"], \"task\": r[\"task\"], \"est_min\": int(r[\"est_min\"]),\n",
        "                \"priority\": r[\"priority\"]\n",
        "            })\n",
        "        user_content = json.dumps({\"today\": today, \"tasks\": items}, ensure_ascii=False)\n",
        "\n",
        "        # ä½¿ç”¨ GenerationConfig å‚³é System Instruction\n",
        "        config = GenerationConfig(\n",
        "            system_instruction=sys_prompt\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            model = genai.GenerativeModel(GEMINI_MODEL)\n",
        "            # å°‡ç³»çµ±æç¤ºå¾ generate_content ç§»é™¤ï¼Œæ”¹ç”¨ config åƒæ•¸\n",
        "            resp = model.generate_content(user_content, config=config)\n",
        "            plan_md = resp.text\n",
        "        except Exception as e:\n",
        "            # ç¢ºä¿éŒ¯èª¤ä¿¡æ¯å°é–‹ç™¼è€…æœ‰å¹«åŠ©\n",
        "            plan_md = f\"âš ï¸ Gemini å¤±æ•—ï¼ˆPlanï¼‰ï¼š{e}\\n\\næ”¹ç”¨è¦å‰‡å¼è¦åŠƒã€‚\"\n",
        "            print(f\"Gemini Plan Error: {e}\")\n",
        "    else:\n",
        "        plan_md = \"ğŸ”§ æœªè¨­å®š GEMINI_API_KEYï¼Œä½¿ç”¨è¦å‰‡å¼è¦åŠƒã€‚\\n\\n\"\n",
        "\n",
        "    # è¦å‰‡å¼ï¼šæŠŠé«˜å„ªå…ˆä»»å‹™å¹³å‡åˆ‡åˆ°ä¸Šåˆ/ä¸‹åˆ/æ™šä¸Š\n",
        "    buckets = {\"morning\": [], \"afternoon\": [], \"evening\": []}\n",
        "\n",
        "    # ä½¿ç”¨å„ªå…ˆç´š H->M->L é †åºæ”¾å…¥ bucket\n",
        "    priority_tasks = cand.sort_values(\"p_ord\", ascending=True)\n",
        "    bucket_keys = [\"morning\", \"afternoon\", \"evening\"]\n",
        "\n",
        "    for i, (_, r) in enumerate(priority_tasks.iterrows()):\n",
        "        bucket_name = bucket_keys[i % 3]\n",
        "        buckets[bucket_name].append(r)\n",
        "\n",
        "    def sec_md(name, rows):\n",
        "        if not rows: return f\"### {name.title()}\\nï¼ˆç„¡ï¼‰\\n\"\n",
        "        lines = [f\"### {name.title()}\"]\n",
        "        for r in rows:\n",
        "            lines.append(f\"- [{r['id']}] {r['task']}ï¼ˆé ä¼° {int(r['est_min'])} åˆ†ï¼ŒP:{r['priority']}ï¼‰\")\n",
        "        return \"\\n\".join(lines) + \"\\n\"\n",
        "\n",
        "    rule_md = sec_md(\"morning\", buckets[\"morning\"]) + \"\\n\" + \\\n",
        "              sec_md(\"afternoon\", buckets[\"afternoon\"]) + \"\\n\" + \\\n",
        "              sec_md(\"evening\", buckets[\"evening\"])\n",
        "\n",
        "    # åªæœ‰åœ¨ AI è¼¸å‡ºä¸æˆåŠŸï¼Œæˆ– API æœªé…ç½®æ™‚ï¼Œæ‰é¡¯ç¤ºè¦å‰‡å¼çµæœ\n",
        "    if not API_KEY_IS_CONFIGURED or plan_md.startswith(\"âš ï¸ Gemini å¤±æ•—\"):\n",
        "        return (plan_md + \"\\n---\\n**ã€è¦å‰‡å¼è¦åŠƒçµæœã€‘**\\n\" + rule_md).strip()\n",
        "    else:\n",
        "        # å¦‚æœ AI æˆåŠŸï¼Œå‰‡ AI è¼¸å‡ºåœ¨å‰ï¼Œè¦å‰‡å¼çµæœåœ¨åˆ†éš”ç·šå¾Œ\n",
        "        return (plan_md + \"\\n\\n---\\n**ã€è¦å‰‡å¼è¦åŠƒçµæœã€‘**\\n\" + rule_md).strip()\n",
        "\n",
        "\n",
        "# ä»Šæ—¥å®Œæˆç‡\n",
        "def today_summary():\n",
        "    global tasks_df\n",
        "    today = tznow().date().isoformat()\n",
        "    planned = tasks_df[\n",
        "        ((tasks_df[\"due_date\"]==today) | (tasks_df[\"planned_for\"].str.lower()==\"today\"))\n",
        "    ]\n",
        "    total = len(planned)\n",
        "\n",
        "    if total == 0:\n",
        "        return \"ğŸ“… ä»Šæ—¥è¨ˆç•«ä»»å‹™ï¼š0ï¼›âœ… å®Œæˆï¼š0ï¼›ğŸ“ˆ å®Œæˆç‡ï¼š0.0%\"\n",
        "\n",
        "    done = planned[planned[\"status\"]==\"done\"]\n",
        "    done_n = len(done)\n",
        "    rate = (done_n/total*100)\n",
        "    return f\"ğŸ“… ä»Šæ—¥è¨ˆç•«ä»»å‹™ï¼š{total}ï¼›âœ… å®Œæˆï¼š{done_n}ï¼›ğŸ“ˆ å®Œæˆç‡ï¼š{rate:.1f}%\"\n",
        "\n",
        "\n",
        "# åŒ¯å‡º\n",
        "def export_data(table_name, format_type):\n",
        "    global tasks_df, logs_df, clips_df, analysis_df\n",
        "\n",
        "    # é¸æ“‡å°æ‡‰çš„ DataFrame\n",
        "    if table_name == \"Tasks\":\n",
        "        df = tasks_df\n",
        "    elif table_name == \"Pomodoro Logs\":\n",
        "        df = logs_df\n",
        "    elif table_name == \"Web Clips\":\n",
        "        df = clips_df\n",
        "    elif table_name == \"Keyword Analysis\":\n",
        "        df = analysis_df # æ–°å¢åŒ¯å‡ºåˆ†æçµæœ\n",
        "    else:\n",
        "        # å¦‚æœæ²’æœ‰é¸ä¸­ä»»ä½•é …ç›®ï¼Œå›å‚³ None å’ŒéŒ¯èª¤è¨Šæ¯\n",
        "        return None, \"âš ï¸ è«‹é¸æ“‡è¦åŒ¯å‡ºçš„è³‡æ–™è¡¨\"\n",
        "\n",
        "    # è™•ç†ç©ºçš„ DataFrame\n",
        "    if df.empty:\n",
        "        # Gradio çš„ gr.File éœ€è¦å›å‚³ None ä¾†æ¸…é™¤/ä¸æä¾›æª”æ¡ˆ\n",
        "        return None, f\"âš ï¸ {table_name} è³‡æ–™è¡¨ç‚ºç©ºï¼Œç„¡æ³•åŒ¯å‡º\"\n",
        "\n",
        "    # æ±ºå®šæª”æ¡ˆåç¨±å’Œå…§å®¹\n",
        "    # ä½¿ç”¨æ—¥æœŸæ™‚é–“ç¢ºä¿æª”æ¡ˆåç¨±å”¯ä¸€æ€§\n",
        "    base_filename = f\"{table_name.lower().replace(' ', '_')}_{dt.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "    if format_type == \"CSV\":\n",
        "        # å„²å­˜ç‚º CSV æª”æ¡ˆ\n",
        "        filepath = f\"{base_filename}.csv\"\n",
        "        # ä½¿ç”¨ encoding='utf-8-sig' ç¢ºä¿åŒ¯å‡ºçš„ CSV åœ¨ Excel ä¸­é–‹å•Ÿæ™‚ä¸­æ–‡ä¸äº‚ç¢¼\n",
        "        df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
        "        return filepath, f\"âœ… å·²åŒ¯å‡º {len(df)} ç­†è³‡æ–™è‡³ {filepath} (CSV æ ¼å¼)\"\n",
        "\n",
        "    elif format_type == \"JSON\":\n",
        "        # å„²å­˜ç‚º JSON æª”æ¡ˆ\n",
        "        filepath = f\"{base_filename}.json\"\n",
        "        # orient='records' æœƒå°‡ DataFrame è½‰ç‚ºé©åˆçš„ JSON åˆ—è¡¨æ ¼å¼\n",
        "        df.to_json(filepath, orient='records', force_ascii=False)\n",
        "        return filepath, f\"âœ… å·²åŒ¯å‡º {len(df)} ç­†è³‡æ–™è‡³ {filepath} (JSON æ ¼å¼)\"\n",
        "\n",
        "    else:\n",
        "        return None, \"âš ï¸ è«‹é¸æ“‡æœ‰æ•ˆçš„åŒ¯å‡ºæ ¼å¼\"\n",
        "\n",
        "# =========================\n",
        "# çˆ¬èŸ²ï¼šæ“·å–æ–‡å­—æˆ–é€£çµä¸¦å¯åŠ å…¥ä»»å‹™ (å·²ç§»é™¤åŠ å…¥ä»»å‹™åŠŸèƒ½)\n",
        "# =========================\n",
        "def crawl(url, selector, mode, limit):\n",
        "    try:\n",
        "        # å¢åŠ  timeout ç¢ºä¿ä¸æœƒç„¡é™æœŸç­‰å¾…\n",
        "        resp = requests.get(url, timeout=15, headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"})\n",
        "        resp.raise_for_status() # æª¢æŸ¥ HTTP ç‹€æ…‹ç¢¼ (200 OK ä»¥å¤–çš„éƒ½æ‹‹å‡ºç•°å¸¸)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        # æ•æ‰æ‰€æœ‰ requests ç›¸é—œçš„ç•°å¸¸ (å¦‚é€£ç·šå¤±æ•—, timeout, 4xx/5xx HTTP éŒ¯èª¤)\n",
        "        error_msg = f\"âš ï¸ è«‹æ±‚å¤±æ•— ({url})ï¼š{type(e).__name__} - {e}\"\n",
        "        print(error_msg)\n",
        "        return pd.DataFrame(columns=CLIPS_HEADER), error_msg\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âš ï¸ è«‹æ±‚å¤±æ•—ï¼šæ„å¤–éŒ¯èª¤ - {e}\"\n",
        "        print(error_msg)\n",
        "        return pd.DataFrame(columns=CLIPS_HEADER), error_msg\n",
        "\n",
        "    # è™•ç†æˆåŠŸçš„å›æ‡‰\n",
        "    try:\n",
        "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "        nodes = soup.select(selector)\n",
        "    except Exception as e:\n",
        "        return pd.DataFrame(columns=CLIPS_HEADER), f\"âš ï¸ è§£æéŒ¯èª¤ï¼šç„¡æ•ˆçš„ Selector æˆ– HTML çµæ§‹ - {e}\"\n",
        "\n",
        "    rows = []\n",
        "    # ç¢ºä¿ limit æ˜¯æœ‰æ•ˆçš„æ•´æ•¸ï¼Œå¦‚æœä¸æ˜¯ï¼Œå‰‡ä½¿ç”¨é è¨­å€¼ 20\n",
        "    try:\n",
        "        limit_n = int(limit) if limit else 20\n",
        "    except ValueError:\n",
        "        limit_n = 20\n",
        "\n",
        "    for i, n in enumerate(nodes[:limit_n]):\n",
        "        text = n.get_text(strip=True) if mode in (\"text\",\"both\") else \"\"\n",
        "        href = n.get(\"href\") if mode in (\"href\",\"both\") else \"\"\n",
        "        # ç›¸å°é€£çµè™•ç†\n",
        "        if href and href.startswith(\"/\"):\n",
        "            from urllib.parse import urljoin\n",
        "            # ç¢ºä¿ urljoin çš„ base url ä¸åŒ…å« / çš„è·¯å¾‘éƒ¨åˆ†\n",
        "            import urllib.parse\n",
        "            parsed_url = urllib.parse.urlparse(url)\n",
        "            base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\"\n",
        "            href = urljoin(base_url, href)\n",
        "\n",
        "        rows.append({\n",
        "            \"clip_id\": str(uuid.uuid4())[:8],\n",
        "            \"url\": url,\n",
        "            \"selector\": selector,\n",
        "            \"text\": text,\n",
        "            \"href\": href,\n",
        "            \"created_at\": tznow().isoformat(),\n",
        "            \"added_to_task\": \"no\" # ä¿ç•™æ¬„ä½ä½†å›ºå®šå¡« no\n",
        "        })\n",
        "    df = pd.DataFrame(rows, columns=CLIPS_HEADER)\n",
        "\n",
        "    if df.empty:\n",
        "        return df, f\"âš ï¸ æ“·å– 0 ç­†ã€‚è«‹æª¢æŸ¥ Selector '{selector}' æ˜¯å¦æ­£ç¢ºã€‚\"\n",
        "\n",
        "    return df, f\"âœ… æˆåŠŸæ“·å– {len(df)} ç­†\"\n",
        "\n",
        "\n",
        "# æ–°å¢åŠŸèƒ½ï¼šåˆ†ææ–‡æœ¬ï¼Œç”¢ç”Ÿç†±è©èˆ‡ AI çµè«–\n",
        "def analyze_text_and_conclude(texts):\n",
        "    global ws_analysis\n",
        "\n",
        "    if not texts:\n",
        "        return \"ï¼ˆç„¡æ–‡æœ¬ï¼‰\", \"âš ï¸ ç„¡æ–‡æœ¬å¯ä¾›åˆ†æ\"\n",
        "\n",
        "    # 1. æ–‡æœ¬åˆä½µèˆ‡åˆ†è©\n",
        "    full_text = \" \".join(texts)\n",
        "    # ä½¿ç”¨ Jieba é€²è¡Œç²¾ç¢ºæ¨¡å¼åˆ†è©\n",
        "    seg_list = jieba.cut(full_text, cut_all=False)\n",
        "\n",
        "    # 2. éæ¿¾åœç”¨è©å’Œå–®å­—è©\n",
        "    words = [\n",
        "        word.strip().lower() for word in seg_list\n",
        "        if word.strip() and len(word.strip()) > 1 and word.strip() not in CHINESE_STOP_WORDS and not word.isdigit()\n",
        "    ]\n",
        "\n",
        "    # 3. è©é »çµ±è¨ˆ (ä½œç‚º TF-IDF çš„ç°¡æ˜“æ›¿ä»£)\n",
        "    word_counts = Counter(words)\n",
        "    top_3 = word_counts.most_common(3)\n",
        "\n",
        "    # æª¢æŸ¥è©æ•¸æ˜¯å¦è¶³å¤ \n",
        "    if len(top_3) < 3:\n",
        "        hot_words = [f\"{item[0]} ({item[1]})\" for item in top_3] + [\"(N/A)\"] * (3 - len(top_3))\n",
        "        conclusion = \"âš ï¸ æ–‡æœ¬è©å½™é‡ä¸è¶³ï¼Œç„¡æ³•ç”Ÿæˆæœ‰æ„ç¾©çš„å­¸è¡“çµè«–ã€‚\"\n",
        "        top_3_clean = [item[0] for item in top_3] + [\"\"] * (3 - len(top_3))\n",
        "    else:\n",
        "        hot_words = [f\"{item[0]} ({item[1]})\" for item in top_3]\n",
        "        hot_words_str = \"ã€\".join([item[0] for item in top_3])\n",
        "        top_3_clean = [item[0] for item in top_3]\n",
        "\n",
        "        # 4. ç”Ÿæˆ AI çµè«–\n",
        "        conclusion = \"âš ï¸ Gemini çµè«–ç”Ÿæˆå¤±æ•—\"\n",
        "\n",
        "        # æª¢æŸ¥ API_KEY_IS_CONFIGURED\n",
        "        if not API_KEY_IS_CONFIGURED:\n",
        "            conclusion = \"ğŸ”§ æœªè¨­å®š GEMINI_API_KEYï¼Œç„¡æ³•ç”Ÿæˆçµè«–ã€‚\"\n",
        "            return f\"ğŸ”¥ ç†±è©ï¼š{hot_words[0]}ã€{hot_words[1]}ã€{hot_words[2]}\", conclusion\n",
        "\n",
        "        # ä½¿ç”¨ GenerationConfig å‚³é System Instruction\n",
        "        sys_prompt = (\n",
        "            \"ä½ æ˜¯ä¸€ä½è³‡æ·±çš„æ–°èåª’é«”ç ”ç©¶å­¸è€…ã€‚è«‹é‡å°ä»¥ä¸‹ç†±è©ï¼Œçµåˆç•¶å‰åª’é«”è¶¨å‹¢å’Œå…¬å…±è¨è«–çš„è„ˆçµ¡ï¼Œ\"\n",
        "            f\"æ’°å¯«ä¸€ç¯‡ç´„120å­—çš„ç²¾ç°¡çµè«–ã€‚è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œä¸¦ä¿æŒå°ˆæ¥­ã€å®¢è§€çš„å­¸è¡“åˆ†æèªæ°£ã€‚\"\n",
        "            f\"é¿å…éåº¦å¼•ç”¨ç†±è©æœ¬èº«ï¼Œè€Œæ˜¯åˆ†æå®ƒå€‘èƒŒå¾Œçš„ç¤¾æœƒæ„ç¾©å’Œåª’é«”ç¾è±¡ã€‚\"\n",
        "        )\n",
        "        user_content = f\"è«‹åˆ†æé€™ä¸‰å€‹ç†±è©ï¼š{hot_words_str}\"\n",
        "\n",
        "        config = GenerationConfig(\n",
        "            system_instruction=sys_prompt\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            model = genai.GenerativeModel(GEMINI_MODEL)\n",
        "            resp = model.generate_content(user_content, config=config)\n",
        "            conclusion = resp.text.strip()\n",
        "        except Exception as e:\n",
        "            conclusion = f\"âš ï¸ Gemini çµè«–ç”Ÿæˆå¤±æ•—ï¼š{e}\"\n",
        "            print(f\"Gemini Analysis Error: {e}\")\n",
        "\n",
        "    # 5. å¯«å…¥åˆ†æçµæœåˆ°æ–°å·¥ä½œè¡¨ (keyword_analysis)\n",
        "    _now = tznow().isoformat()\n",
        "    new_row = pd.DataFrame([{\n",
        "        \"timestamp\": _now,\n",
        "        \"hot_word_1\": top_3_clean[0],\n",
        "        \"hot_word_2\": top_3_clean[1],\n",
        "        \"hot_word_3\": top_3_clean[2],\n",
        "        # å„²å­˜å‰ 20 å€‹è©é »æœ€é«˜çš„è©å½™åŠå…¶è¨ˆæ•¸\n",
        "        \"word_list_json\": json.dumps(word_counts.most_common(20), ensure_ascii=False),\n",
        "        \"gemini_conclusion\": conclusion\n",
        "    }])\n",
        "\n",
        "    # è®€å–ç¾æœ‰åˆ†ææ•¸æ“šä¸¦é™„åŠ æ–°çµæœ\n",
        "    global analysis_df\n",
        "    # ç¢ºä¿ analysis_df æ˜¯æœ€æ–°çš„ï¼Œå› ç‚ºæˆ‘å€‘éœ€è¦åœ¨å®ƒå¾Œé¢è¿½åŠ \n",
        "    analysis_df = read_df(ws_analysis, ANALYSIS_HEADER)\n",
        "    analysis_df = pd.concat([analysis_df, new_row], ignore_index=True)\n",
        "    write_df(ws_analysis, analysis_df, ANALYSIS_HEADER)\n",
        "    # è¿”å›ç†±è©å­—ä¸²å’Œçµè«–\n",
        "    return f\"ğŸ”¥ ç†±è©ï¼š{hot_words[0]}ã€{hot_words[1]}ã€{hot_words[2]}\", conclusion\n",
        "\n",
        "def _crawl_analyze_and_save(u, s, m, l):\n",
        "    \"\"\"åŸ·è¡Œçˆ¬èŸ²ï¼Œä¿å­˜çµæœï¼Œä¸¦é€²è¡Œæ–‡æœ¬åˆ†æå’Œçµè«–ç”Ÿæˆ\"\"\"\n",
        "    df, msg = crawl(u, s, m, l)\n",
        "\n",
        "    # å¯«å…¥ web_clips\n",
        "    global clips_df\n",
        "    clips_df = df.copy() # <--- é—œéµï¼šä½¿ç”¨ copy() ç¢ºä¿ç¨ç«‹çš„ Dataframe ä¾› Gradio é¡¯ç¤º\n",
        "    write_df(ws_clips, clips_df, CLIPS_HEADER)\n",
        "\n",
        "    hot_words_str = \"ï¼ˆç„¡ï¼‰\"\n",
        "    conclusion = \"âš ï¸ æ“·å–çµæœä¸­ç„¡æœ‰æ•ˆæ–‡æœ¬ï¼Œç„¡æ³•é€²è¡Œåˆ†æã€‚\"\n",
        "\n",
        "    # é€²è¡Œæ–‡æœ¬åˆ†æèˆ‡çµè«–ç”Ÿæˆ\n",
        "    if not df.empty:\n",
        "        # ç¯©é¸å‡ºæœ‰æ–‡æœ¬çš„é …ç›®\n",
        "        texts_to_analyze = [r['text'] for _, r in df.iterrows() if r['text'].strip()]\n",
        "\n",
        "        if texts_to_analyze:\n",
        "            # analyze_text_and_conclude æœƒæ›´æ–°å…¨å±€çš„ analysis_df\n",
        "            hot_words_str, conclusion = analyze_text_and_conclude(texts_to_analyze)\n",
        "            msg += f\"ã€‚å·²æˆåŠŸåˆ†æ {len(texts_to_analyze)} ç­†æ–‡æœ¬ã€‚\"\n",
        "        else:\n",
        "             msg += \"ã€‚æ“·å–çµæœä¸­ç„¡æœ‰æ•ˆæ–‡æœ¬å¯ä¾›åˆ†æã€‚\"\n",
        "    else:\n",
        "        msg += \"ã€‚ç„¡æ–‡æœ¬å¯ä¾›åˆ†æã€‚\"\n",
        "\n",
        "    # æ›´æ–° Analysis Dataframe é¡¯ç¤º\n",
        "    global analysis_df\n",
        "    # é€™è£¡å¿…é ˆé‡æ–°å¾ Sheet è®€å–ï¼Œå› ç‚º analyze_text_and_conclude å·²ç¶“å¯«å…¥ä¸¦æ›´æ–°äº† analysis_df\n",
        "    # ç‚ºäº† Gradio é¡¯ç¤ºï¼Œæˆ‘å€‘ç¢ºä¿è¿”å›çš„éƒ½æ˜¯æœ€æ–°çš„ Dataframe å‰¯æœ¬\n",
        "    analysis_df = read_df(ws_analysis, ANALYSIS_HEADER)\n",
        "\n",
        "    # è¿”å› 5 å€‹å€¼ï¼Œç¢ºä¿ Dataframe ä½¿ç”¨ .copy()\n",
        "    return msg, clips_df.copy(), hot_words_str, conclusion, analysis_df.copy()\n",
        "\n",
        "# =========================\n",
        "# Gradio ä»‹é¢\n",
        "# =========================\n",
        "def _refresh():\n",
        "    global tasks_df, logs_df, clips_df, analysis_df\n",
        "    tasks_df, logs_df, clips_df, analysis_df = refresh_all()\n",
        "    choices = list_task_choices()\n",
        "    # å›å‚³ 8 å€‹è¼¸å‡ºï¼šgrid_tasks, grid_logs, grid_clips, grid_analysis, task_choice, out_summary, sel_task, task_choice_del\n",
        "    return (\n",
        "        tasks_df.copy(),\n",
        "        logs_df.copy(),\n",
        "        clips_df.copy(),\n",
        "        analysis_df.copy(),\n",
        "        gr.update(choices=choices),\n",
        "        today_summary(),\n",
        "        gr.update(choices=choices),\n",
        "        gr.update(choices=choices)\n",
        "    )\n",
        "\n",
        "with gr.Blocks(title=\"å¾…è¾¦æ¸…å–®ï¼‹ç•ªèŒ„é˜ï¼‹AI è¨ˆç•«ï¼ˆSheet/Gradio/çˆ¬èŸ²ï¼‰\") as demo:\n",
        "    gr.Markdown(\"# âœ… å¾…è¾¦æ¸…å–®èˆ‡ç•ªèŒ„é˜ï¼ˆGoogle Sheetï¼‹Gradioï¼‹Crawlerï¼‹AI è¨ˆç•«ï¼‰\")\n",
        "    with gr.Row():\n",
        "        btn_refresh = gr.Button(\"ğŸ”„ é‡æ–°æ•´ç†ï¼ˆSheet â†’ Appï¼‰\")\n",
        "        out_summary = gr.Markdown(today_summary())\n",
        "\n",
        "    with gr.Tab(\"Tasks\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=2):\n",
        "                task = gr.Textbox(label=\"ä»»å‹™åç¨±\", placeholder=\"å¯« HW3 å ±å‘Š / ä¿®æ­£ SQL / â€¦\")\n",
        "                priority = gr.Dropdown([\"H\",\"M\",\"L\"], value=\"M\", label=\"å„ªå…ˆç´š\")\n",
        "                est_min = gr.Number(value=25, label=\"é ä¼°æ™‚é–“ï¼ˆåˆ†é˜ï¼‰\", precision=0)\n",
        "                due_date = gr.Textbox(label=\"åˆ°æœŸæ—¥ï¼ˆYYYY-MM-DDï¼Œå¯ç©ºç™½ï¼‰\")\n",
        "                labels = gr.Textbox(label=\"æ¨™ç±¤ï¼ˆé€—è™Ÿåˆ†éš”ï¼Œå¯ç©ºç™½ï¼‰\")\n",
        "                notes = gr.Textbox(label=\"å‚™è¨»ï¼ˆå¯ç©ºç™½ï¼‰\")\n",
        "                planned_for = gr.Dropdown([\"\",\"today\",\"tomorrow\"], value=\"\", label=\"è¦åŠƒæ­¸å±¬\")\n",
        "                btn_add = gr.Button(\"â• æ–°å¢ä»»å‹™\")\n",
        "                msg_add = gr.Markdown()\n",
        "            with gr.Column(scale=3):\n",
        "                # ç¢ºä¿ Dataframe ä½¿ç”¨ copy()\n",
        "                grid_tasks = gr.Dataframe(value=tasks_df.copy(), label=\"ä»»å‹™æ¸…å–®ï¼ˆç›´æ¥å¾ Sheet ä¾†ï¼‰\", interactive=False)\n",
        "\n",
        "        with gr.Row():\n",
        "            task_choice = gr.Dropdown(choices=list_task_choices(), label=\"é¸å–ä»»å‹™ï¼ˆç”¨æ–¼æ›´æ–°ï¼‰\")\n",
        "            new_status = gr.Dropdown([\"todo\",\"in-progress\",\"done\"], value=\"in-progress\", label=\"æ›´æ–°ç‹€æ…‹\")\n",
        "            btn_update = gr.Button(\"âœï¸ æ›´æ–°ç‹€æ…‹\")\n",
        "            btn_done = gr.Button(\"âœ… ç›´æ¥æ¨™è¨˜å®Œæˆ\")\n",
        "\n",
        "        with gr.Row():\n",
        "            task_choice_del = gr.Dropdown(choices=list_task_choices(), label=\"é¸å–ä»»å‹™ï¼ˆç”¨æ–¼åˆªé™¤ï¼‰\")\n",
        "            btn_delete = gr.Button(\"ğŸ—‘ï¸ åˆªé™¤è©²ä»»å‹™\")\n",
        "            msg_delete = gr.Markdown()\n",
        "\n",
        "\n",
        "        msg_update = gr.Markdown()\n",
        "\n",
        "    with gr.Tab(\"Pomodoro\"):\n",
        "        gr.Markdown(\"## ğŸ… ç•ªèŒ„é˜è¨ˆæ™‚èˆ‡ç´€éŒ„\")\n",
        "        with gr.Row():\n",
        "            sel_task = gr.Dropdown(choices=list_task_choices(), label=\"é¸æ“‡ä»»å‹™\")\n",
        "            cycles = gr.Number(value=1, precision=0, label=\"ç•ªèŒ„æ•¸ï¼ˆåƒ…ä½œç´€éŒ„ï¼‰\")\n",
        "        with gr.Row():\n",
        "            btn_start_work = gr.Button(\"â–¶ï¸ é–‹å§‹å·¥ä½œ (25min)\")\n",
        "            note_work = gr.Textbox(label=\"å·¥ä½œå‚™è¨»ï¼ˆå¯ç©ºç™½ï¼‰\")\n",
        "            btn_end_work = gr.Button(\"â¹ï¸ çµæŸå·¥ä½œä¸¦è¨˜éŒ„\")\n",
        "        with gr.Row():\n",
        "            btn_start_break = gr.Button(\"ğŸµ é–‹å§‹ä¼‘æ¯ (5min)\")\n",
        "            note_break = gr.Textbox(label=\"ä¼‘æ¯å‚™è¨»ï¼ˆå¯ç©ºç™½ï¼‰\")\n",
        "            btn_end_break = gr.Button(\"â¹ï¸ çµæŸä¼‘æ¯ä¸¦è¨˜éŒ„\")\n",
        "        # é€™è£¡çš„ msg_pomo æ¥æ”¶ start_phase å’Œ end_phase çš„å›å‚³å€¼\n",
        "        msg_pomo = gr.Markdown()\n",
        "        # ç¢ºä¿ Dataframe ä½¿ç”¨ copy()\n",
        "        grid_logs = gr.Dataframe(value=logs_df.copy(), label=\"ç•ªèŒ„é˜ç´€éŒ„\", interactive=False)\n",
        "\n",
        "    with gr.Tab(\"AI Plan\"):\n",
        "        # é¡¯ç¤º API ç‹€æ…‹ï¼Œæä¾›æ›´æ¸…æ™°çš„æŒ‡å¼•\n",
        "        api_status = \"âœ… API é‡‘é‘°å·²é…ç½®\" if API_KEY_IS_CONFIGURED else \"âŒ è­¦å‘Šï¼šAPI é‡‘é‘°æœªé…ç½®ï¼Œå°‡ä½¿ç”¨è¦å‰‡å¼è¦åŠƒã€‚\"\n",
        "        gr.Markdown(f\"## ğŸ§  ä»Šæ—¥ AI è¡Œå‹•è¨ˆç•«\\n**æ¨¡å‹ï¼š{GEMINI_MODEL}**\\n{api_status}\\næŠŠ**ä»Šå¤©çš„ä»»å‹™**æ’æˆ **morning / afternoon / evening** ä¸‰æ®µè¡Œå‹•è¨ˆç•«ã€‚\")\n",
        "        btn_plan = gr.Button(\"ğŸ§  ç”¢ç”Ÿä»Šæ—¥è¨ˆç•«\")\n",
        "        out_plan = gr.Markdown()\n",
        "\n",
        "    with gr.Tab(\"Crawler\"):\n",
        "        gr.Markdown(\"## ğŸ•·ï¸ ç¶²ç«™æ“·å–èˆ‡ç†±è©åˆ†æ\")\n",
        "        url = gr.Textbox(label=\"ç›®æ¨™ URL\", placeholder=\"https://example.com/news\", value=\"https://tw.news.yahoo.com/\")\n",
        "        selector = gr.Textbox(label=\"CSS Selector\", placeholder=\"h3.Mb\\\\(5px\\\\) a / a\", value=\"h3.Mb\\\\(5px\\\\) a\")\n",
        "        mode = gr.Radio([\"text\",\"href\",\"both\"], value=\"text\", label=\"æ“·å–å…§å®¹\")\n",
        "        limit = gr.Number(value=20, precision=0, label=\"æœ€å¤šæ“·å–å¹¾ç­†\")\n",
        "        btn_crawl = gr.Button(\"ğŸ•·ï¸ é–‹å§‹æ“·å–èˆ‡åˆ†æ\")\n",
        "        msg_crawl = gr.Markdown()\n",
        "        # ç¢ºä¿ Dataframe ä½¿ç”¨ copy()\n",
        "        grid_clips = gr.Dataframe(value=clips_df.copy(), label=\"æ“·å–çµæœï¼ˆåªä¿ç•™æœ€æ–°çµæœï¼ŒæœƒåŒæ­¥å¯«å…¥ Web Clips å·¥ä½œè¡¨ï¼‰\", interactive=False)\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\"### ğŸ“° æ–‡æœ¬åˆ†æèˆ‡å­¸è¡“çµè«–\")\n",
        "        out_hot_words = gr.Textbox(label=\"å‰ 3 å¤§ç†±è© (è©å½™ (è©é »))\", interactive=False)\n",
        "        out_gemini_conclusion = gr.Markdown(label=\"æ–°èåª’é«”ç ”ç©¶å­¸è€…çµè«–ï¼ˆå·²å¯«å…¥ keyword_analysis å·¥ä½œè¡¨ï¼‰\")\n",
        "\n",
        "\n",
        "    with gr.Tab(\"Analysis Results\"): # æ–°å¢ä¸€å€‹ Tab ä¾†é¡¯ç¤ºåˆ†æçµæœçš„å·¥ä½œè¡¨å…§å®¹\n",
        "        gr.Markdown(\"## ğŸ“Š é—œéµå­—åˆ†ææ­·å²ç´€éŒ„\")\n",
        "        # ç¢ºä¿ Dataframe ä½¿ç”¨ copy()\n",
        "        grid_analysis = gr.Dataframe(value=analysis_df.copy(), label=\"ç†±è©åˆ†æç´€éŒ„ï¼ˆä¾†è‡ª keyword_analysis å·¥ä½œè¡¨ï¼‰\", interactive=False)\n",
        "\n",
        "\n",
        "    with gr.Tab(\"Summary\"):\n",
        "        btn_summary = gr.Button(\"ğŸ“Š é‡æ–°è¨ˆç®—ä»Šæ—¥å®Œæˆç‡\")\n",
        "        out_summary2 = gr.Markdown()\n",
        "\n",
        "\n",
        "\n",
        "    #åŒ¯å‡º\n",
        "    with gr.Tab(\"Export Data\"):\n",
        "        gr.Markdown(\"## ğŸ’¾ è³‡æ–™åŒ¯å‡º (Export Data)\")\n",
        "        with gr.Row():\n",
        "            export_table = gr.Radio(\n",
        "                choices=[\"Tasks\", \"Pomodoro Logs\", \"Web Clips\", \"Keyword Analysis\"], # æ–°å¢é¸é …\n",
        "                value=\"Tasks\",\n",
        "                label=\"é¸æ“‡è¦åŒ¯å‡ºçš„è³‡æ–™è¡¨\"\n",
        "            )\n",
        "            export_format = gr.Radio(\n",
        "                choices=[\"CSV\", \"JSON\"],\n",
        "                value=\"CSV\",\n",
        "                label=\"é¸æ“‡åŒ¯å‡ºæ ¼å¼\"\n",
        "            )\n",
        "        btn_export = gr.Button(\"â¬‡ï¸ åŒ¯å‡ºè³‡æ–™\")\n",
        "        msg_export = gr.Markdown(\"é¸æ“‡è³‡æ–™è¡¨å’Œæ ¼å¼ï¼Œç„¶å¾Œé»æ“Šã€ŒåŒ¯å‡ºè³‡æ–™ã€ã€‚\")\n",
        "        # ä½¿ç”¨ gr.File ä½œç‚ºè¼¸å‡ºï¼Œè®“ä½¿ç”¨è€…å¯ä»¥ç›´æ¥ä¸‹è¼‰æª”æ¡ˆ\n",
        "        file_output = gr.File(label=\"ä¸‹è¼‰åŒ¯å‡ºçš„æª”æ¡ˆ\", type=\"filepath\")\n",
        "\n",
        "    # === ç¶å®šå‹•ä½œ ===\n",
        "    # æ›´æ–° _refresh ç¶å®šè¼¸å‡º\n",
        "    btn_refresh.click(_refresh, outputs=[grid_tasks, grid_logs, grid_clips, grid_analysis, task_choice, out_summary, sel_task, task_choice_del])\n",
        "\n",
        "    btn_add.click(\n",
        "        add_task,\n",
        "        inputs=[task, priority, est_min, due_date, labels, notes, planned_for],\n",
        "        outputs=[msg_add, grid_tasks]\n",
        "    )\n",
        "\n",
        "    btn_update.click(\n",
        "        update_task_status,\n",
        "        inputs=[task_choice, new_status],\n",
        "        outputs=[msg_update, grid_tasks]\n",
        "    )\n",
        "\n",
        "    btn_done.click(\n",
        "        mark_done,\n",
        "        inputs=[task_choice],\n",
        "        outputs=[msg_update, grid_tasks]\n",
        "    )\n",
        "\n",
        "    btn_delete.click(\n",
        "        delete_task,\n",
        "        inputs=[task_choice_del],\n",
        "        # è¼¸å‡ºï¼šè¨Šæ¯ (msg_delete)ï¼Œä»»å‹™ Dataframe (grid_tasks)ï¼Œä¸¦æ›´æ–°ä¸‰å€‹ä¸‹æ‹‰é¸å–® (task_choice, sel_task, task_choice_del)\n",
        "        outputs=[msg_delete, grid_tasks, task_choice, sel_task, task_choice_del]\n",
        "    )\n",
        "\n",
        "    # ç¶å®šç•ªèŒ„é˜åŠŸèƒ½ (ä¿®æ­£è¼¸å‡ºæ•¸é‡ä»¥åŒ…å« grid_logs)\n",
        "    # Start Phase åªéœ€è¦è¼¸å‡ºè¨Šæ¯\n",
        "    btn_start_work.click(\n",
        "        start_phase, inputs=[sel_task, gr.State(\"work\"), cycles], outputs=[msg_pomo]\n",
        "    )\n",
        "    # End Phase éœ€è¦è¼¸å‡ºè¨Šæ¯å’Œ logs Dataframe\n",
        "    btn_end_work.click(\n",
        "        end_phase, inputs=[sel_task, note_work], outputs=[msg_pomo, grid_logs]\n",
        "    )\n",
        "    # Start Phase åªéœ€è¦è¼¸å‡ºè¨Šæ¯\n",
        "    btn_start_break.click(\n",
        "        start_phase, inputs=[sel_task, gr.State(\"break\"), cycles], outputs=[msg_pomo]\n",
        "    )\n",
        "    # End Phase éœ€è¦è¼¸å‡ºè¨Šæ¯å’Œ logs Dataframe\n",
        "    btn_end_break.click(\n",
        "        end_phase, inputs=[sel_task, note_break], outputs=[msg_pomo, grid_logs]\n",
        "    )\n",
        "\n",
        "    btn_plan.click(generate_today_plan, outputs=[out_plan])\n",
        "\n",
        "    # ç¶å®šåŒ¯å‡ºè³‡æ–™æŒ‰éˆ•\n",
        "    btn_export.click(\n",
        "        export_data,\n",
        "        inputs=[export_table, export_format],\n",
        "        outputs=[file_output, msg_export] # è¼¸å‡ºæª”æ¡ˆè·¯å¾‘åˆ° gr.Fileï¼Œè¼¸å‡ºè¨Šæ¯åˆ° gr.Markdown\n",
        "    )\n",
        "\n",
        "    # ç¶å®šæ–°çš„çˆ¬èŸ²èˆ‡åˆ†æå‡½æ•¸ (ç¢ºä¿è¼¸å‡ºæ•¸é‡å’Œé †åºæ­£ç¢º)\n",
        "    btn_crawl.click(\n",
        "        _crawl_analyze_and_save,\n",
        "        inputs=[url, selector, mode, limit],\n",
        "        # è¼¸å‡ºé †åºï¼šè¨Šæ¯, clips_df, hot_words_str, conclusion, analysis_df\n",
        "        outputs=[msg_crawl, grid_clips, out_hot_words, out_gemini_conclusion, grid_analysis]\n",
        "    )\n",
        "\n",
        "    btn_summary.click(today_summary, outputs=[out_summary2])\n",
        "\n",
        "demo.launch(share=True) # å»ºè­°é–‹å•Ÿ share=True è®“æ‚¨å¯ä»¥åœ¨å¤–éƒ¨æ¸¬è©¦"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "B-j_nkkznCav",
        "outputId": "6f5c7a41-a924-4af2-e4a7-58e3f84d617b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3dda0ab4b7230d5c65.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3dda0ab4b7230d5c65.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'gradio' has no attribute 'blocks'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1313387556.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0mbtn_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoday_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_summary2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshare\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# å»ºè­°é–‹å•Ÿ share=True è®“æ‚¨å¯ä»¥åœ¨å¤–éƒ¨æ¸¬è©¦\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/blocks.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[0m\n\u001b[1;32m   2848\u001b[0m                 \u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m             }\n\u001b[0;32m-> 2850\u001b[0;31m             \u001b[0manalytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunched_analytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2852\u001b[0m         \u001b[0mis_in_interactive_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ps1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/analytics.py\u001b[0m in \u001b[0;36mlaunched_analytics\u001b[0;34m(blocks, data)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mcore_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_block_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcore_gradio_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     additional_data = {\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mcore_gradio_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    667\u001b[0m     return [\n\u001b[1;32m    668\u001b[0m         \u001b[0mclass_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_all_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradio.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gradio/utils.py\u001b[0m in \u001b[0;36mget_all_components\u001b[0;34m()\u001b[0m\n\u001b[1;32m    641\u001b[0m     classes_to_check = (\n\u001b[1;32m    642\u001b[0m         \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mComponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;34m+\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlockContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m     )\n\u001b[1;32m    645\u001b[0m     \u001b[0msubclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'blocks'"
          ]
        }
      ]
    }
  ]
}